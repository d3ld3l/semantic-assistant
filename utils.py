# utils.py
import pandas as pd
import requests
import re
from io import BytesIO
from sentence_transformers import SentenceTransformer, util

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# –°—Å—ã–ª–∫–∏ –Ω–∞ —Ñ–∞–π–ª—ã
GITHUB_CSV_URLS = [
    "https://raw.githubusercontent.com/d3ld3l/semantic-assistant/main/data1.xlsx",
    "https://raw.githubusercontent.com/d3ld3l/semantic-assistant/main/data2.xlsx",
    "https://raw.githubusercontent.com/d3ld3l/semantic-assistant/main/data3.xlsx"
]

# –°–ª–æ–≤–∞—Ä—å —Å–∏–Ω–æ–Ω–∏–º–æ–≤ (—Ä—É—á–Ω–æ–π)
SYNONYM_DICT = {
    "—Å–∏–º–∫–∞": "—Å–∏–º–∫–∞—Ä—Ç–∞",
    "–∫—Ä–µ–¥–∏—Ç–∫–∞": "–∫—Ä–µ–¥–∏—Ç–Ω–∞—è –∫–∞—Ä—Ç–∞",
    "–ø—ç–π": "pay",
    "—Ç–µ–ª–µ2": "tele2",
}

def preprocess(text):
    text = str(text).lower().strip()
    text = re.sub(r"\s+", " ", text)
    for short, full in SYNONYM_DICT.items():
        text = text.replace(short, full)
    return text

def load_excel(url):
    response = requests.get(url)
    if response.status_code != 200:
        raise ValueError(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}")
    df = pd.read_excel(BytesIO(response.content))
    
    topic_cols = [col for col in df.columns if col.lower().startswith("topics")]
    if not topic_cols:
        raise KeyError("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ topics")

    df = df[['phrase'] + topic_cols]
    df['topics'] = df[topic_cols].fillna('').agg(lambda x: [t for t in x.tolist() if t], axis=1)
    df['phrase_proc'] = df['phrase'].apply(preprocess)
    return df[['phrase', 'phrase_proc', 'topics']]

def load_all_excels():
    dfs = []
    for url in GITHUB_CSV_URLS:
        try:
            df = load_excel(url)
            dfs.append(df)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å {url}: {e}")
    if not dfs:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
    return pd.concat(dfs, ignore_index=True)

def semantic_search(query, df, top_k=5, threshold=0.5):
    query_proc = preprocess(query)
    query_emb = model.encode(query_proc, convert_to_tensor=True)
    phrase_embs = model.encode(df['phrase_proc'].tolist(), convert_to_tensor=True)

    sims = util.pytorch_cos_sim(query_emb, phrase_embs)[0]
    results = []

    for idx, score in enumerate(sims):
        score = float(score)
        if score >= threshold:
            phrase = df.iloc[idx]['phrase']
            topics = df.iloc[idx]['topics']
            results.append((score, phrase, topics))

    results.sort(key=lambda x: x[0], reverse=True)
    top_results = results[:top_k]

    # üîç –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ ‚Äî —Ç–æ—á–Ω—ã–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Å–ª–æ–≤–∞ (–¥–æ 8 —Å–∏–º–≤–æ–ª–æ–≤)
    if len(query.strip().split()) == 1 and len(query.strip()) <= 8:
        exact_matches = df[df['phrase_proc'].str.contains(rf'\b{re.escape(query_proc)}\b', regex=True)]
        for _, row in exact_matches.iterrows():
            if row['phrase'] not in [r[1] for r in top_results]:
                top_results.append((0.0, row['phrase'], row['topics']))  # 0.0 ‚Äî —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ —ç—Ç–æ –Ω–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π

    return top_results
